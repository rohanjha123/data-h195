{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b118f060-17fe-4e66-8a3d-e4d96ef70a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181bf73-4eb4-439e-8c91-149d9a45252f",
   "metadata": {},
   "source": [
    "## PSET 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c62d192-74c1-4960-aa01-b5a4ab6ce2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>married</th>\n",
       "      <th>wage</th>\n",
       "      <th>exper</th>\n",
       "      <th>age</th>\n",
       "      <th>coll</th>\n",
       "      <th>games</th>\n",
       "      <th>minutes</th>\n",
       "      <th>guard</th>\n",
       "      <th>forward</th>\n",
       "      <th>center</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>assists</th>\n",
       "      <th>draft</th>\n",
       "      <th>allstar</th>\n",
       "      <th>avgmin</th>\n",
       "      <th>black</th>\n",
       "      <th>children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1002.5</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>2867</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>2789</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>1178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>2096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>2638</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1</td>\n",
       "      <td>715.0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>1084</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>2113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     married    wage  exper  age  coll  games  minutes  guard  forward  \\\n",
       "0          1  1002.5      4   27     4     77     2867      1        0   \n",
       "1          1  2030.0      5   28     4     78     2789      1        0   \n",
       "2          0   650.0      1   25     4     74     1149      0        0   \n",
       "3          0  2030.0      5   28     4     47     1178      0        1   \n",
       "4          0   755.0      3   24     4     82     2096      1        0   \n",
       "..       ...     ...    ...  ...   ...    ...      ...    ...      ...   \n",
       "264        1  3210.0      7   29     4     79     2638      1        0   \n",
       "265        1   715.0      5   31     4     75     1084      0        1   \n",
       "266        1   600.0     11   33     3     67     1197      1        0   \n",
       "267        0  2500.0      6   28     4     78     2113      0        0   \n",
       "268        0  2000.0     12   33     3     30      282      0        1   \n",
       "\n",
       "     center  points  rebounds  assists  draft  allstar  avgmin  black  \\\n",
       "0         0      16         4        5   19.0        0   37.23      1   \n",
       "1         0      13         3        9   28.0        0   35.76      1   \n",
       "2         1       6         3        0   19.0        0   15.53      1   \n",
       "3         0       7         5        2    1.0        0   25.06      1   \n",
       "4         0      11         4        3   24.0        0   25.56      1   \n",
       "..      ...     ...       ...      ...    ...      ...     ...    ...   \n",
       "264       0      20         3        3   11.0        1   33.39      1   \n",
       "265       0       5         3        1   54.0        0   14.45      1   \n",
       "266       0      10         2        2    4.0        0   17.87      1   \n",
       "267       1      16         6        2    2.0        0   27.09      0   \n",
       "268       0       2         3        1    5.0        0    9.40      1   \n",
       "\n",
       "     children  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "..        ...  \n",
       "264         0  \n",
       "265         1  \n",
       "266         1  \n",
       "267         0  \n",
       "268         0  \n",
       "\n",
       "[269 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba = pd.read_csv(\"nba.csv\")\n",
    "nba#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7111e7d-fa5b-4c69-aa79-6a3de519d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(string, df_name = 'df'):\n",
    "    print(\"import numpy as np\")\n",
    "    print(\"from scipy import stats\")\n",
    "    eq_var = True\n",
    "    nan_pol = 'propagate'\n",
    "\n",
    "    string = string.replace(\"ttest \", \"\")\n",
    "    catvar_split = string.split(\"(\")\n",
    "    catvar = catvar_split[-1].split(\")\")[0]\n",
    "    if catvar_split[-1].split(\")\")[1].strip() == 'unequal':\n",
    "        eq_var = False\n",
    "    catvar_split[0] = \"(\".join(catvar_split[:-1])\n",
    "    var = catvar_split[0].split(\",\")[0]\n",
    "    if 'if !missing' in var:\n",
    "        var = var.split(\" \")[0]\n",
    "        nan_pol = 'omit'    \n",
    "    print(\"### First, we must filter the DataFrame to obtain the right values\")\n",
    "    print(f\"catvar_vals = np.unique({df_name}['{catvar}'])\")\n",
    "    print(f\"df_1 = {df_name}[{df_name}['{catvar}'] == catvar_vals[0]]\")\n",
    "    print(f\"df_2 = {df_name}[{df_name}['{catvar}'] == catvar_vals[1]]\")\n",
    "    print(\"### Then, we can run our t-test\")\n",
    "    print(f\"stats.ttest_ind(df_1['{var}'], df_2['{var}'], equal_var={eq_var}, nan_policy='{nan_pol}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33adbb4a-7e0e-4934-8f3d-13ad446d9489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from scipy import stats\n",
      "### First, we must filter the DataFrame to obtain the right values\n",
      "catvar_vals = np.unique(nba['guard'])\n",
      "df_1 = nba[nba['guard'] == catvar_vals[0]]\n",
      "df_2 = nba[nba['guard'] == catvar_vals[1]]\n",
      "### Then, we can run our t-test\n",
      "stats.ttest_ind(df_1['wage'], df_2['wage'], equal_var=True, nan_policy='propagate')\n"
     ]
    }
   ],
   "source": [
    "ttest(\"ttest wage, by(guard)\",\"nba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3adb136b-7865-41b6-ac42-981c17496a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from scipy import stats\n",
      "### First, we must filter the DataFrame to obtain the right values\n",
      "catvar_vals = np.unique(nba['guard'])\n",
      "df_1 = nba[nba['guard'] == catvar_vals[0]]\n",
      "df_2 = nba[nba['guard'] == catvar_vals[1]]\n",
      "### Then, we can run our t-test\n",
      "stats.ttest_ind(df_1['wage'], df_2['wage'], equal_var=False, nan_policy='propagate')\n"
     ]
    }
   ],
   "source": [
    "ttest(\"ttest wage, by(guard) unequal\", \"nba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39eba4fb-754e-49d9-a496-dd50e79b1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1c, 1e\n",
    "\n",
    "def filter_gen(df_name, string):\n",
    "    if string.startswith(\"gen\"):\n",
    "        string = string.replace(\"gen \", \"\")\n",
    "        str_split = string.split(\"=\",1)\n",
    "        str_split = [x.strip() for x in str_split]\n",
    "        new_col_name = str_split[0]\n",
    "        if str_split[1].count(\"=\")>0:\n",
    "            if str_split[1].startswith(\"(\"):\n",
    "                str_split[1] = str_split[1][1:-1]\n",
    "            filter_split = str_split[1].split(\" \", 1)\n",
    "            new_string = f\"{df_name}['{new_col_name}'] = {df_name}['{filter_split[0]}'] {filter_split[1]}\"\n",
    "            new_string_split = new_string.split(\" = \", 1)\n",
    "            print(new_string)\n",
    "        else:\n",
    "            words_lst = re.findall(r'\\w\\w+',str_split[1])\n",
    "            for word in words_lst:\n",
    "                if word not in ['log']:\n",
    "                    str_split[1] = str_split[1].replace(word, f\"{df_name}['{word}']\")\n",
    "                else:\n",
    "                    str_split[1] = str_split[1].replace(word, f\"np.{word}\")\n",
    "            new_string = f\"{df_name}['{new_col_name}'] = {str_split[1]}\"\n",
    "            print(new_string)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d663e7d-39b5-4399-b9ea-5dc16349359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba['degree'] = nba['coll'] >= 4\n"
     ]
    }
   ],
   "source": [
    "filter_gen(\"nba\",\"gen degree = (coll >= 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a41684e-4569-4418-b5cf-fe26923847fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba['productivity'] = nba['points']/(nba['minutes']/nba['games'])\n"
     ]
    }
   ],
   "source": [
    "filter_gen(\"nba\",\"gen productivity = points/(minutes/games)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd8cc3e-ae86-4c0d-85b1-a0b5bfc34a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1g\n",
    "\n",
    "def corr(df_name, string):\n",
    "    if string.startswith(\"corr\"):\n",
    "        string = string.replace(\"corr \", \"\")\n",
    "        words_lst = re.findall(r'[a-zA-Z]+',string)\n",
    "        print(f\"{df_name}[{words_lst}].corr()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "279e95c8-895f-4d1c-9dca-478ad7d97f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba[['points', 'assists', 'rebounds']].corr()\n"
     ]
    }
   ],
   "source": [
    "corr(\"nba\",\"corr points assists rebounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6046839-63c2-4f10-921c-b0b209a2a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba['index'] = nba['points'] + nba['rebounds'] + 2*nba['assists']\n"
     ]
    }
   ],
   "source": [
    "filter_gen(\"nba\",\"gen index = points + rebounds + 2*assists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246da76e-66c8-46fd-8fc3-d35ef2514c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba['payoff'] = nba['index']/nba['wage']\n"
     ]
    }
   ],
   "source": [
    "filter_gen(\"nba\",\"gen payoff = index/wage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "236fc16f-c170-48aa-8e1c-faa2c59181e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>countryname</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gdppc</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2pc</th>\n",
       "      <th>population</th>\n",
       "      <th>oecd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>9.799629e+09</td>\n",
       "      <td>741.4421</td>\n",
       "      <td>2427.554</td>\n",
       "      <td>0.183669</td>\n",
       "      <td>13216985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>PYF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>883.747</td>\n",
       "      <td>3.296764</td>\n",
       "      <td>268065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>MCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36845</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>UKR</td>\n",
       "      <td>9.057726e+10</td>\n",
       "      <td>1974.6212</td>\n",
       "      <td>304804.720</td>\n",
       "      <td>6.644867</td>\n",
       "      <td>45870700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Venezuela, RB</td>\n",
       "      <td>VEN</td>\n",
       "      <td>1.750000e+11</td>\n",
       "      <td>6010.0270</td>\n",
       "      <td>201747.340</td>\n",
       "      <td>6.946437</td>\n",
       "      <td>29043283</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       countryname countrycode           gdp      gdppc         co2  \\\n",
       "0  2010            Zambia         ZMB  9.799629e+09   741.4421    2427.554   \n",
       "1  2010  French Polynesia         PYF           NaN        NaN     883.747   \n",
       "2  2010            Monaco         MCO           NaN        NaN         NaN   \n",
       "3  2010           Ukraine         UKR  9.057726e+10  1974.6212  304804.720   \n",
       "4  2010     Venezuela, RB         VEN  1.750000e+11  6010.0270  201747.340   \n",
       "\n",
       "      co2pc  population  oecd  \n",
       "0  0.183669    13216985   0.0  \n",
       "1  3.296764      268065   0.0  \n",
       "2       NaN       36845   0.0  \n",
       "3  6.644867    45870700   0.0  \n",
       "4  6.946437    29043283   0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollution = pd.read_csv(\"pollution.csv\")\n",
    "pollution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0441613b-3c14-4269-9d0f-b2bc268b68e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catvar_vals = np.unique(pollution['oecd'])\n",
      "if len(catvar_vals) != 2:\n",
      "    raise ValueError(f'The categorical variable (oecd) doesn\\'t have 2 groups')\n",
      "df_1 = pollution[pollution['oecd'] == catvar_vals[0]]\n",
      "df_2 = pollution[pollution['oecd'] == catvar_vals[1]]\n",
      "ttest = stats.ttest_ind(df_1['co2pc'], df_2['co2pc'], equal_var=False, nan_policy='omit')\n",
      "t_stat = ttest.statistic\n",
      "p_val = ttest.pvalue\n",
      "print(f'T-stat: {t_stat}, P-value: {p_val}')\n"
     ]
    }
   ],
   "source": [
    "ttest(\"ttest co2pc if !missing(countrycode), by(oecd) unequal\", \"pollution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7c72f32-b40b-494e-b4d2-3d51968ee147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-5.682465161974536, pvalue=2.683581293169389e-07, df=71.47718715993969)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catvar_vals = np.unique(pollution['oecd'])\n",
    "if len(catvar_vals) != 2:\n",
    "    raise ValueError(f'The categorical variable (oecd) doesn\\'t have 2 groups')\n",
    "df_1 = pollution[pollution['oecd'] == catvar_vals[0]]\n",
    "df_2 = pollution[pollution['oecd'] == catvar_vals[1]]\n",
    "stats.ttest_ind(df_1['co2pc'], df_2['co2pc'], equal_var=False, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c541c4-0282-450a-b714-76c563100b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pollution['log_gdp'] = np.log(pollution['gdp'])\n",
      "pollution['log_co2'] = np.log(pollution['co2'])\n"
     ]
    }
   ],
   "source": [
    "filter_gen(\"pollution\",\"gen log_gdp = log(gdp)\")\n",
    "filter_gen(\"pollution\",\"gen log_co2 = log(co2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20479ded-356a-4727-99a1-5c2663bbca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution['log_gdp'] = np.log(pollution['gdp'])\n",
    "pollution['log_co2'] = np.log(pollution['co2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce719364-fda7-472a-a91e-acf0bbdb4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(string, df_name = 'df'):\n",
    "    if string.startswith(\"twoway\"):\n",
    "        string = string.replace(\"twoway (\",\"\")[:-2]\n",
    "        command = string.split(\",\")[0].strip()\n",
    "        customizations = string.split(\",\")[1].strip()\n",
    "        df = eval(df_name)\n",
    "        if command.startswith(\"scatter\"):\n",
    "            var_1 = command.split(\" \")[1]\n",
    "            var_2 = command.split(\" \")[2]\n",
    "            print(f\"plt.scatter({df_name}['{var_1}'], {df_name}['{var_2}']);\")\n",
    "        customizations_split = customizations.split(\")\")\n",
    "        for word in customizations_split:\n",
    "            word = word.strip()\n",
    "            if word.startswith(\"xtitle\"):\n",
    "                xtitle = word.split(\"(\")[1]\n",
    "                if xtitle.startswith(\"'\"):\n",
    "                    xtitle = xtitle[1:]\n",
    "                if xtitle.endswith(\"'\"):\n",
    "                    xtitle = xtitle[:-1]\n",
    "                print(f\"plt.xlabel('{xtitle}');\")\n",
    "            if word.startswith(\"ytitle\"):\n",
    "                ytitle = word.split(\"(\")[1]\n",
    "                if ytitle.startswith(\"'\"):\n",
    "                    ytitle = ytitle[1:]\n",
    "                if ytitle.endswith(\"'\"):\n",
    "                    ytitle = ytitle[:-1]\n",
    "                print(f\"plt.ylabel('{ytitle}');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca110239-5d6c-4d92-b3a3-2d3d122f5ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plt.scatter(pollution['log_gdp'], pollution['log_co2']);\n",
      "plt.xlabel('log gdp');\n",
      "plt.ylabel('log co2');\n"
     ]
    }
   ],
   "source": [
    "scatter(\"twoway (scatter log_gdp log_co2, xtitle('log gdp') ytitle('log co2'))\",\"pollution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37e1c7a5-4bc2-4dbf-a230-34d589c685ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v</th>\n",
       "      <th>x</th>\n",
       "      <th>u</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.497907</td>\n",
       "      <td>19.958145</td>\n",
       "      <td>-34.342513</td>\n",
       "      <td>95.448213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643911</td>\n",
       "      <td>22.878215</td>\n",
       "      <td>83.974146</td>\n",
       "      <td>228.365219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.597268</td>\n",
       "      <td>21.945360</td>\n",
       "      <td>50.444549</td>\n",
       "      <td>190.171347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863052</td>\n",
       "      <td>27.261030</td>\n",
       "      <td>202.860614</td>\n",
       "      <td>369.165766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027564</td>\n",
       "      <td>10.551286</td>\n",
       "      <td>9.351561</td>\n",
       "      <td>92.107991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          v          x           u           y\n",
       "0  0.497907  19.958145  -34.342513   95.448213\n",
       "1  0.643911  22.878215   83.974146  228.365219\n",
       "2  0.597268  21.945360   50.444549  190.171347\n",
       "3  0.863052  27.261030  202.860614  369.165766\n",
       "4  0.027564  10.551286    9.351561   92.107991"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.random.random_sample(100)\n",
    "x = 10 + 20 * v\n",
    "u = np.random.normal(0, 100, 100)\n",
    "y = 30 + 5 * x + u\n",
    "df_all = pd.DataFrame(data={'v':v, 'x':x,'u':u,'y':y})\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dffef6f1-2440-4f7d-937f-022e758d8785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plt.scatter(df_all['x'], df_all['y']);\n",
      "plt.xlabel('x');\n",
      "plt.ylabel('y');\n"
     ]
    }
   ],
   "source": [
    "scatter(df_name=\"df_all\", string='twoway (scatter x y, xtitle(x) ytitle(y))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e421799-3605-4fe6-b886-17cbb80609ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(string, df_name='df'):\n",
    "    if string.startswith('describe'):\n",
    "        print(f'{df_name}.describe()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dbc964a-bf38-4fdf-81e3-16a4e00e56cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hispanic</th>\n",
       "      <th>citizen</th>\n",
       "      <th>black</th>\n",
       "      <th>exp</th>\n",
       "      <th>wage</th>\n",
       "      <th>female</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.288462</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8.461538</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>10.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.634615</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.365385</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hispanic  citizen  black   exp       wage  female  education\n",
       "0         1        1      0  14.0   5.288462       1          9\n",
       "1         0        1      0  14.7   8.461538       1         13\n",
       "2         0        1      0  14.7  10.416667       1         13\n",
       "3         0        1      0  14.0  21.634615       1         14\n",
       "4         1        0      0  12.0   3.365385       1         12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la = pd.read_csv(\"la.csv\")\n",
    "la.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42965970-6fcd-4afe-b4be-4a5c75c83683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la.describe()\n"
     ]
    }
   ],
   "source": [
    "describe(\"describe\",\"la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ed6bea-ad44-47c5-a145-12c0644825bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(string, df_name='df'):\n",
    "    if string.startswith('histogram'):\n",
    "        string = string.replace('histogram ','')\n",
    "        str_split = string.split(\", \")\n",
    "        num_bins_change = False\n",
    "        num_bins = 0\n",
    "        for word in str_split:\n",
    "            if word.startswith(\"bin\"):\n",
    "                num_bins_change = True\n",
    "                num_bins = int(word.split(\"(\")[1].split(\")\")[0])\n",
    "        if num_bins_change == False:\n",
    "            print(f\"{df_name}.hist(column='{str_split[0]}');\")\n",
    "        else:\n",
    "            print(f\"{df_name}.hist(column='{str_split[0]}',bins={num_bins});\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e7efa15-af2b-45cc-9765-b77fa5102630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la.hist(column='wage',bins=80);\n"
     ]
    }
   ],
   "source": [
    "hist(\"histogram wage, bin(80)\",\"la\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097a82d-f823-43bb-ab43-bd3b34c7d2c0",
   "metadata": {},
   "source": [
    "## PSET 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b6c453d-62b8-4f54-ac87-5992582f5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.random_sample(100)\n",
    "x = 10 + 20 * v\n",
    "u = np.random.normal(0, 100, 100)\n",
    "y = 30 + 5 * x + u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17d9d63c-5f45-4a9d-b7c1-d5b319675e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(string, df_name = 'df'):\n",
    "    print(\"import statsmodels.api as sm\")\n",
    "    string = string[4:]\n",
    "    clustering_vars = ''\n",
    "    first_half, second_half = string, string\n",
    "    if \",\" in string:\n",
    "        first_half = string.split(\",\")[0]\n",
    "        second_half = string.split(\",\")[1]\n",
    "    if \"if\" in first_half:\n",
    "        print(\"### We first filter the DataFrame\")\n",
    "        if_statement = first_half.split(\"if\")[1].strip()\n",
    "        first_half = first_half.split(\"if\")[0].strip()\n",
    "        if \"=\" in if_statement:\n",
    "            splitted_if = if_statement.split(\"=\")\n",
    "            print(f\"{df_name}_filtered = {df_name}[{df_name}['{splitted_if[0].strip()}'] == {splitted_if[1].strip()}]\")\n",
    "        elif \"<\" in if_statement:\n",
    "            splitted_if = if_statement.split(\"<\")\n",
    "            print(f\"{df_name}_filtered = {df_name}[{df_name}['{splitted_if[0].strip()}'] < {splitted_if[1].strip()}]\")\n",
    "        elif \">\" in if_statement:\n",
    "            splitted_if = if_statement.split(\">\")\n",
    "            print(f\"{df_name}_filtered = {df_name}[{df_name}['{splitted_if[0].strip()}'] > {splitted_if[1].strip()}]\")\n",
    "        else:\n",
    "            raise ValueError(f'Could not interpret if statement')\n",
    "        df_name = df_name + \"_filtered\"\n",
    "    y_var = first_half.split(\" \")[0]\n",
    "    x_var = \"'\" + \"', '\".join(first_half.split(\" \")[1:]) + \"'\"\n",
    "    if \"vce\" in second_half and \"cluster\" in second_half:\n",
    "        print(\"### We first perform some string manipulations to ensure we are appropripately accounting for strings. This section seems complicated as this code is meant to be a general-purpose code for converting the Stata commands to Python. You can greatly simplify this step if you know exactly which variables you are interested in; simply extract those variables from the DataFrame directly. \")\n",
    "        print(f\"y_var = \\\"{y_var}\\\"\")\n",
    "        second_half_split = second_half.split(\"cluster\")\n",
    "        clustering_vars = second_half_split[1][:-1].strip().split(\" \")\n",
    "        print(f\"clustering_vars = {clustering_vars}\")\n",
    "    if ' ' not in x_var:\n",
    "        if clustering_vars:\n",
    "            x_var_temp = x_var + \", '\" + \"', '\".join(clustering_vars) + \"'\"\n",
    "            print(\"### Dropping NaN/missing values\")\n",
    "            print(f\"{df_name}_no_na = {df_name}[[{x_var_temp},'{y_var}']].dropna()\")\n",
    "        else:\n",
    "            print(\"### Dropping NaN/missing values\")\n",
    "            print(f\"{df_name}_no_na = {df_name}[[{x_var},'{y_var}']].dropna()\")\n",
    "        df_name = df_name + \"_no_na\"\n",
    "        print(\"### Below, we extract the relevant variables from the DataFrame\")\n",
    "        print(f\"x_df = {df_name}[{x_var}]\")\n",
    "    elif \"i.\" in x_var:\n",
    "        #raise ValueError(f'Indicators are currently not supported')\n",
    "        print(f\"{df_name}_with_dummies = {df_name}.copy()\")\n",
    "        df_name = df_name + \"_with_dummies\"\n",
    "        print(f\"x_var = \\\"{x_var}\\\"\")\n",
    "        x_var_new = \"'\" + \"', '\".join([i.strip(\"'\") for i in x_var.split(\", \") if not i.strip(\"'\").startswith(\"i.\")]) + \"'\"\n",
    "        print(\"x_var_new = \\\"'\\\" + \\\"', '\\\".join([i.strip(\\\"'\\\") for i in x_var.split(\\\", \\\") if not i.strip(\\\"'\\\").startswith(\\\"i.\\\")]) + \\\"'\\\"\")\n",
    "        print(\"### The below section adds in relevant indicator variables, ensuring they have interpretable names\")\n",
    "        print(f\"indicator_list = [m.strip(\\\"'\\\") for m in x_var.split('i.')[1:]]\")\n",
    "        print(\"for indicator in indicator_list:\")\n",
    "        print(f\"    dummies = pd.get_dummies({df_name}[indicator])\")\n",
    "        print(f\"    dummies = dummies.iloc[:,1:]\")\n",
    "        print(f\"    dummies.columns = [str(x) + '_' + str(indicator) for x in dummies.columns]\")\n",
    "        print(f\"    {df_name} = pd.concat([{df_name},dummies],axis=1)\")\n",
    "        print(\"    x_var_new = x_var_new + \\\", '\\\" + \\\"', '\\\".join(dummies.columns) + \\\"'\\\"\")\n",
    "        print(\"x_var = x_var_new\")\n",
    "        print(\"### This helps ensure the clustered variables are extracted from the DataFrame\")\n",
    "        print(\"if clustering_vars:\")\n",
    "        print(\"    x_var_temp = x_var + \\\", '\\\" + \\\"', '\\\".join(clustering_vars) + \\\"'\\\"\")\n",
    "        if clustering_vars:\n",
    "            x_var_temp = x_var + \", '\" + \"', '\".join(clustering_vars) + \"'\"\n",
    "            print(f\"var_list = x_var_temp +\\\", '\\\"+ str(y_var) + \\\"'\\\"\")\n",
    "            print(\"### Dropping NaN/missing values\")\n",
    "            print(f\"{df_name}_no_na = {df_name}[[i.strip(\\\"'\\\") for i in var_list.split(\\\", \\\")]].dropna()\")\n",
    "        else:\n",
    "            print(\"### Dropping NaN/missing values\")\n",
    "            print(f\"{df_name}_no_na = {df_name}[[{x_var},'{y_var}']].dropna()\")\n",
    "        df_name = df_name + \"_no_na\"\n",
    "        print(\"### Below, we extract the relevant variables from the DataFrame\")\n",
    "        print(f\"x_df = {df_name}[[i.strip(\\\"'\\\") for i in x_var.split(\\\", \\\")]]\")\n",
    "    else:\n",
    "        if clustering_vars:\n",
    "            x_var_temp = x_var + \", '\" + \"', '\".join(clustering_vars) + \"'\"\n",
    "            print(\"### Dropping NaN/missing values\")\n",
    "            print(f\"{df_name}_no_na = {df_name}[[{x_var_temp},'{y_var}']].dropna()\")\n",
    "        else:\n",
    "            print(\"### Dropping NaN/missing values\")\n",
    "            print(f\"{df_name}_no_na = {df_name}[[{x_var},'{y_var}']].dropna()\")\n",
    "        df_name = df_name + \"_no_na\"\n",
    "        print(\"### Below, we extract the relevant variables from the DataFrame\")\n",
    "        print(f\"x_df = {df_name}[[{x_var}]]\")\n",
    "    print(f\"y_df = {df_name}['{y_var}']\")\n",
    "    print(\"### We now define the model, fit it to the data and then view a summary of the results\")\n",
    "    if 'noconstant' in second_half:\n",
    "        print(\"model = sm.OLS(y_df, x_df)\")\n",
    "    else:\n",
    "        print(\"model = sm.OLS(y_df, sm.add_constant(x_df))\")\n",
    "    if \"vce\" not in second_half:\n",
    "        print(\"result = model.fit()\")\n",
    "    elif \"vce\" in second_half and \"robust\" in second_half:\n",
    "        print(\"result = model.fit(cov_type='HC1')\")\n",
    "    elif \"vce\" in second_half and \"cluster\" in second_half:\n",
    "        print(f\"result = model.fit(cov_type='cluster', cov_kwds={{'groups': {df_name}{clustering_vars}}})\")\n",
    "    else:\n",
    "        raise ValueError(f'VCE type not recognized')\n",
    "    print(\"result.summary()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf62bc55-f8fc-4f62-8583-b3bebac770fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import statsmodels.api as sm\n",
      "### Dropping NaN/missing values\n",
      "la_no_na = la[['exp','wage']].dropna()\n",
      "### Below, we extract the relevant variables from the DataFrame\n",
      "x_df = la_no_na['exp']\n",
      "y_df = la_no_na['wage']\n",
      "### We now define the model, fit it to the data and then view a summary of the results\n",
      "model = sm.OLS(y_df, sm.add_constant(x_df))\n",
      "result = model.fit()\n",
      "result.summary()\n"
     ]
    }
   ],
   "source": [
    "reg(\"reg wage exp\", \"la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98f83a40-6111-456e-bda2-240a0c28e3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.4714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 03 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.493</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:18:22</td>     <th>  Log-Likelihood:    </th> <td> -3541.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   863</td>      <th>  AIC:               </th> <td>   7086.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   861</td>      <th>  BIC:               </th> <td>   7096.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   16.0816</td> <td>    3.917</td> <td>    4.105</td> <td> 0.000</td> <td>    8.393</td> <td>   23.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp</th>   <td>   -0.2135</td> <td>    0.311</td> <td>   -0.687</td> <td> 0.493</td> <td>   -0.824</td> <td>    0.397</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1263.062</td> <th>  Durbin-Watson:     </th>  <td>   1.830</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>413853.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.176</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>109.028</td> <th>  Cond. No.          </th>  <td>    99.5</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       wage       & \\textbf{  R-squared:         } &     0.001   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &    -0.001   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &    0.4714   \\\\\n",
       "\\textbf{Date:}             & Sat, 03 Feb 2024 & \\textbf{  Prob (F-statistic):} &    0.493    \\\\\n",
       "\\textbf{Time:}             &     12:18:22     & \\textbf{  Log-Likelihood:    } &   -3541.0   \\\\\n",
       "\\textbf{No. Observations:} &         863      & \\textbf{  AIC:               } &     7086.   \\\\\n",
       "\\textbf{Df Residuals:}     &         861      & \\textbf{  BIC:               } &     7096.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      16.0816  &        3.917     &     4.105  &         0.000        &        8.393    &       23.771     \\\\\n",
       "\\textbf{exp}   &      -0.2135  &        0.311     &    -0.687  &         0.493        &       -0.824    &        0.397     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1263.062 & \\textbf{  Durbin-Watson:     } &     1.830   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 413853.334  \\\\\n",
       "\\textbf{Skew:}          &   8.176  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      & 109.028  & \\textbf{  Cond. No.          } &      99.5   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   wage   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                    0.4714\n",
       "Date:                Sat, 03 Feb 2024   Prob (F-statistic):              0.493\n",
       "Time:                        12:18:22   Log-Likelihood:                -3541.0\n",
       "No. Observations:                 863   AIC:                             7086.\n",
       "Df Residuals:                     861   BIC:                             7096.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         16.0816      3.917      4.105      0.000       8.393      23.771\n",
       "exp           -0.2135      0.311     -0.687      0.493      -0.824       0.397\n",
       "==============================================================================\n",
       "Omnibus:                     1263.062   Durbin-Watson:                   1.830\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           413853.334\n",
       "Skew:                           8.176   Prob(JB):                         0.00\n",
       "Kurtosis:                     109.028   Cond. No.                         99.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "### Dropping NaN/missing values\n",
    "la_no_na = la[['exp','wage']].dropna()\n",
    "### Below, we extract the relevant variables from the DataFrame\n",
    "x_df = la_no_na['exp']\n",
    "y_df = la_no_na['wage']\n",
    "### We now define the model, fit it to the data and then view a summary of the results\n",
    "model = sm.OLS(y_df, sm.add_constant(x_df))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1f44584-94a4-414f-9ffc-41ffb23d1272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import statsmodels.api as sm\n",
      "### We first perform some string manipulations to ensure we are appropripately accounting for strings. This section seems complicated as this code is meant to be a general-purpose code for converting the Stata commands to Python. You can greatly simplify this step if you know exactly which variables you are interested in; simply extract those variables from the DataFrame directly. \n",
      "y_var = \"wage\"\n",
      "clustering_vars = ['education']\n",
      "la_with_dummies = la.copy()\n",
      "x_var = \"'exp', 'i.female'\"\n",
      "x_var_new = \"'\" + \"', '\".join([i.strip(\"'\") for i in x_var.split(\", \") if not i.strip(\"'\").startswith(\"i.\")]) + \"'\"\n",
      "### The below section adds in relevant indicator variables, ensuring they have interpretable names\n",
      "indicator_list = [m.strip(\"'\") for m in x_var.split('i.')[1:]]\n",
      "for indicator in indicator_list:\n",
      "    dummies = pd.get_dummies(la_with_dummies[indicator])\n",
      "    dummies = dummies.iloc[:,1:]\n",
      "    dummies.columns = [str(x) + '_' + str(indicator) for x in dummies.columns]\n",
      "    la_with_dummies = pd.concat([la_with_dummies,dummies],axis=1)\n",
      "    x_var_new = x_var_new + \", '\" + \"', '\".join(dummies.columns) + \"'\"\n",
      "x_var = x_var_new\n",
      "### This helps ensure the clustered variables are extracted from the DataFrame\n",
      "if clustering_vars:\n",
      "    x_var_temp = x_var + \", '\" + \"', '\".join(clustering_vars) + \"'\"\n",
      "var_list = x_var_temp +\", '\"+ str(y_var) + \"'\"\n",
      "### Dropping NaN/missing values\n",
      "la_with_dummies_no_na = la_with_dummies[[i.strip(\"'\") for i in var_list.split(\", \")]].dropna()\n",
      "### Below, we extract the relevant variables from the DataFrame\n",
      "x_df = la_with_dummies_no_na[[i.strip(\"'\") for i in x_var.split(\", \")]]\n",
      "y_df = la_with_dummies_no_na['wage']\n",
      "### We now define the model, fit it to the data and then view a summary of the results\n",
      "model = sm.OLS(y_df, sm.add_constant(x_df))\n",
      "result = model.fit(cov_type='cluster', cov_kwds={'groups': la_with_dummies_no_na['education']})\n",
      "result.summary()\n"
     ]
    }
   ],
   "source": [
    "reg(\"reg wage exp i.female, vce(cluster education)\", \"la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "381906a8-cadb-433c-9f88-5b35eeb29ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 03 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.183</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:18:13</td>     <th>  Log-Likelihood:    </th> <td> -3538.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   863</td>      <th>  AIC:               </th> <td>   7082.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   860</td>      <th>  BIC:               </th> <td>   7096.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>   17.4218</td> <td>    3.698</td> <td>    4.712</td> <td> 0.000</td> <td>   10.175</td> <td>   24.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp</th>      <td>   -0.2373</td> <td>    0.206</td> <td>   -1.153</td> <td> 0.249</td> <td>   -0.640</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1_female</th> <td>   -2.4604</td> <td>    1.261</td> <td>   -1.951</td> <td> 0.051</td> <td>   -4.932</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1260.198</td> <th>  Durbin-Watson:     </th>  <td>   1.842</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>409372.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.142</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>108.449</td> <th>  Cond. No.          </th>  <td>    101.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       wage       & \\textbf{  R-squared:         } &     0.007   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.005   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     1.993   \\\\\n",
       "\\textbf{Date:}             & Sat, 03 Feb 2024 & \\textbf{  Prob (F-statistic):} &    0.183    \\\\\n",
       "\\textbf{Time:}             &     12:18:13     & \\textbf{  Log-Likelihood:    } &   -3538.0   \\\\\n",
       "\\textbf{No. Observations:} &         863      & \\textbf{  AIC:               } &     7082.   \\\\\n",
       "\\textbf{Df Residuals:}     &         860      & \\textbf{  BIC:               } &     7096.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &     cluster      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}     &      17.4218  &        3.698     &     4.712  &         0.000        &       10.175    &       24.669     \\\\\n",
       "\\textbf{exp}       &      -0.2373  &        0.206     &    -1.153  &         0.249        &       -0.640    &        0.166     \\\\\n",
       "\\textbf{1\\_female} &      -2.4604  &        1.261     &    -1.951  &         0.051        &       -4.932    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1260.198 & \\textbf{  Durbin-Watson:     } &     1.842   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 409372.994  \\\\\n",
       "\\textbf{Skew:}          &   8.142  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      & 108.449  & \\textbf{  Cond. No.          } &      101.   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are robust to cluster correlation (cluster)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   wage   R-squared:                       0.007\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     1.993\n",
       "Date:                Sat, 03 Feb 2024   Prob (F-statistic):              0.183\n",
       "Time:                        12:18:13   Log-Likelihood:                -3538.0\n",
       "No. Observations:                 863   AIC:                             7082.\n",
       "Df Residuals:                     860   BIC:                             7096.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:              cluster                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         17.4218      3.698      4.712      0.000      10.175      24.669\n",
       "exp           -0.2373      0.206     -1.153      0.249      -0.640       0.166\n",
       "1_female      -2.4604      1.261     -1.951      0.051      -4.932       0.011\n",
       "==============================================================================\n",
       "Omnibus:                     1260.198   Durbin-Watson:                   1.842\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           409372.994\n",
       "Skew:                           8.142   Prob(JB):                         0.00\n",
       "Kurtosis:                     108.449   Cond. No.                         101.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "### We first perform some string manipulations to ensure we are appropripately accounting for strings. This section seems complicated as this code is meant to be a general-purpose code for converting the Stata commands to Python. You can greatly simplify this step if you know exactly which variables you are interested in; simply extract those variables from the DataFrame directly. \n",
    "y_var = \"wage\"\n",
    "clustering_vars = ['education']\n",
    "la_with_dummies = la.copy()\n",
    "x_var = \"'exp', 'i.female'\"\n",
    "x_var_new = \"'\" + \"', '\".join([i.strip(\"'\") for i in x_var.split(\", \") if not i.strip(\"'\").startswith(\"i.\")]) + \"'\"\n",
    "### The below section adds in relevant indicator variables, ensuring they have interpretable names\n",
    "indicator_list = [m.strip(\"'\") for m in x_var.split('i.')[1:]]\n",
    "for indicator in indicator_list:\n",
    "    dummies = pd.get_dummies(la_with_dummies[indicator])\n",
    "    dummies = dummies.iloc[:,1:]\n",
    "    dummies.columns = [str(x) + '_' + str(indicator) for x in dummies.columns]\n",
    "    la_with_dummies = pd.concat([la_with_dummies,dummies],axis=1)\n",
    "    x_var_new = x_var_new + \", '\" + \"', '\".join(dummies.columns) + \"'\"\n",
    "x_var = x_var_new\n",
    "### This helps ensure the clustered variables are extracted from the DataFrame\n",
    "if clustering_vars:\n",
    "    x_var_temp = x_var + \", '\" + \"', '\".join(clustering_vars) + \"'\"\n",
    "var_list = x_var_temp +\", '\"+ str(y_var) + \"'\"\n",
    "### Dropping NaN/missing values\n",
    "la_with_dummies_no_na = la_with_dummies[[i.strip(\"'\") for i in var_list.split(\", \")]].dropna()\n",
    "### Below, we extract the relevant variables from the DataFrame\n",
    "x_df = la_with_dummies_no_na[[i.strip(\"'\") for i in x_var.split(\", \")]]\n",
    "y_df = la_with_dummies_no_na['wage']\n",
    "### We now define the model, fit it to the data and then view a summary of the results\n",
    "model = sm.OLS(y_df, sm.add_constant(x_df))\n",
    "result = model.fit(cov_type='cluster', cov_kwds={'groups': la_with_dummies_no_na['education']})\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d2786fc-f6dc-4619-bda8-f87fa0ae6ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 03 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.183</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:51:19</td>     <th>  Log-Likelihood:    </th> <td> -3538.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   863</td>      <th>  AIC:               </th> <td>   7082.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   860</td>      <th>  BIC:               </th> <td>   7096.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>   17.4218</td> <td>    3.698</td> <td>    4.712</td> <td> 0.000</td> <td>   10.175</td> <td>   24.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp</th>      <td>   -0.2373</td> <td>    0.206</td> <td>   -1.153</td> <td> 0.249</td> <td>   -0.640</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1_female</th> <td>   -2.4604</td> <td>    1.261</td> <td>   -1.951</td> <td> 0.051</td> <td>   -4.932</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1260.198</td> <th>  Durbin-Watson:     </th>  <td>   1.842</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>409372.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.142</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>108.449</td> <th>  Cond. No.          </th>  <td>    101.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       wage       & \\textbf{  R-squared:         } &     0.007   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.005   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     1.993   \\\\\n",
       "\\textbf{Date:}             & Sat, 03 Feb 2024 & \\textbf{  Prob (F-statistic):} &    0.183    \\\\\n",
       "\\textbf{Time:}             &     11:51:19     & \\textbf{  Log-Likelihood:    } &   -3538.0   \\\\\n",
       "\\textbf{No. Observations:} &         863      & \\textbf{  AIC:               } &     7082.   \\\\\n",
       "\\textbf{Df Residuals:}     &         860      & \\textbf{  BIC:               } &     7096.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &     cluster      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}     &      17.4218  &        3.698     &     4.712  &         0.000        &       10.175    &       24.669     \\\\\n",
       "\\textbf{exp}       &      -0.2373  &        0.206     &    -1.153  &         0.249        &       -0.640    &        0.166     \\\\\n",
       "\\textbf{1\\_female} &      -2.4604  &        1.261     &    -1.951  &         0.051        &       -4.932    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1260.198 & \\textbf{  Durbin-Watson:     } &     1.842   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 409372.994  \\\\\n",
       "\\textbf{Skew:}          &   8.142  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      & 108.449  & \\textbf{  Cond. No.          } &      101.   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are robust to cluster correlation (cluster)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   wage   R-squared:                       0.007\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     1.993\n",
       "Date:                Sat, 03 Feb 2024   Prob (F-statistic):              0.183\n",
       "Time:                        11:51:19   Log-Likelihood:                -3538.0\n",
       "No. Observations:                 863   AIC:                             7082.\n",
       "Df Residuals:                     860   BIC:                             7096.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:              cluster                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         17.4218      3.698      4.712      0.000      10.175      24.669\n",
       "exp           -0.2373      0.206     -1.153      0.249      -0.640       0.166\n",
       "1_female      -2.4604      1.261     -1.951      0.051      -4.932       0.011\n",
       "==============================================================================\n",
       "Omnibus:                     1260.198   Durbin-Watson:                   1.842\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           409372.994\n",
       "Skew:                           8.142   Prob(JB):                         0.00\n",
       "Kurtosis:                     108.449   Cond. No.                         101.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_var = \"wage\"\n",
    "clustering_vars = ['education']\n",
    "la_with_dummies = la.copy()\n",
    "x_var = \"'exp', 'i.female'\"\n",
    "x_var_new = \"'\" + \"', '\".join([i.strip(\"'\") for i in x_var.split(\", \") if not i.strip(\"'\").startswith(\"i.\")]) + \"'\"\n",
    "indicator_list = [m.strip(\"'\") for m in x_var.split('i.')[1:]]\n",
    "for indicator in indicator_list:\n",
    "    dummies = pd.get_dummies(la_with_dummies[indicator])\n",
    "    dummies = dummies.iloc[:,1:]\n",
    "    dummies.columns = [str(x) + '_' + str(indicator) for x in dummies.columns]\n",
    "    la_with_dummies = pd.concat([la_with_dummies,dummies],axis=1)\n",
    "    x_var_new = x_var_new + \", '\" + \"', '\".join(dummies.columns) + \"'\"\n",
    "x_var = x_var_new\n",
    "if clustering_vars:\n",
    "    x_var_temp = x_var + \", '\" + \"', '\".join(clustering_vars) + \"'\"\n",
    "var_list = x_var_temp +\", '\"+ str(y_var) + \"'\"\n",
    "la_with_dummies_no_na = la_with_dummies[[i.strip(\"'\") for i in var_list.split(\", \")]].dropna()\n",
    "x_df = la_with_dummies_no_na[[i.strip(\"'\") for i in x_var.split(\", \")]]\n",
    "y_df = la_with_dummies_no_na['wage']\n",
    "model = sm.OLS(y_df, sm.add_constant(x_df))\n",
    "result = model.fit(cov_type='cluster', cov_kwds={'groups': la_with_dummies_no_na['education']})\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76ffce-7ba8-44ce-a74f-837acdc555d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn-env]",
   "language": "python",
   "name": "conda-env-sklearn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
