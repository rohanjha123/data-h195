{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04170fb-c4f3-4610-a7a8-bf1d21d7ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800e1999-0004-420d-9b17-0fc7723ede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 1000 random employee IDs\n",
    "employee_ids = np.arange(1, 1001)\n",
    "\n",
    "# Generate random ages following a normal distribution\n",
    "ages = np.random.normal(loc=35, scale=5, size=1000).astype(int)\n",
    "\n",
    "# Generate random salaries following a right-skewed distribution\n",
    "salaries = np.random.lognormal(mean=10, sigma=0.5, size=1000).astype(int)\n",
    "\n",
    "# Generate random years of experience following a uniform distribution\n",
    "experience_years = np.random.randint(0, 31, size=1000)\n",
    "\n",
    "# Generate random performance scores following a normal distribution\n",
    "performance_scores = np.random.normal(loc=75, scale=10, size=1000)\n",
    "\n",
    "# Generate a categorical 'Location' variable with 3 locations\n",
    "locations = np.random.choice(['NY', 'LA', 'Chicago'], size=1000)\n",
    "\n",
    "# Generate random department labels for each employee\n",
    "departments = np.random.choice(['HR', 'Finance', 'Marketing', 'Engineering', 'Sales'], size=1000)\n",
    "\n",
    "# Create a DataFrame with the generated data\n",
    "data = {\n",
    "    'Employee_ID': employee_ids,\n",
    "    'Age': ages,\n",
    "    'Salary': salaries,\n",
    "    'Experience_Years': experience_years,\n",
    "    'Performance_Score': performance_scores,\n",
    "    'Department': departments,  # Categorical variable\n",
    "    'Location': locations  # New categorical variable 'Location'\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b502da-5bed-4637-99b1-22f6cae6f76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Performance_Score</td> <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>  -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td> 0.02232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 20 Jan 2024</td>  <th>  Prob (F-statistic):</th>  <td> 0.888</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:13:55</td>      <th>  Log-Likelihood:    </th> <td> -3732.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>       <th>  AIC:               </th> <td>   7468.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>       <th>  BIC:               </th> <td>   7478.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>cluster</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>   75.2876</td> <td>    1.010</td> <td>   74.559</td> <td> 0.000</td> <td>   73.309</td> <td>   77.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Salary</th> <td>-5.786e-06</td> <td> 3.87e-05</td> <td>   -0.149</td> <td> 0.881</td> <td>-8.17e-05</td> <td> 7.01e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.167</td> <th>  Durbin-Watson:     </th> <td>   2.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.920</td> <th>  Jarque-Bera (JB):  </th> <td>   0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.030</td> <th>  Prob(JB):          </th> <td>   0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.967</td> <th>  Cond. No.          </th> <td>6.28e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)<br/>[2] The condition number is large, 6.28e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & Performance\\_Score & \\textbf{  R-squared:         } &     0.000   \\\\\n",
       "\\textbf{Model:}            &        OLS         & \\textbf{  Adj. R-squared:    } &    -0.001   \\\\\n",
       "\\textbf{Method:}           &   Least Squares    & \\textbf{  F-statistic:       } &   0.02232   \\\\\n",
       "\\textbf{Date:}             &  Sat, 20 Jan 2024  & \\textbf{  Prob (F-statistic):} &    0.888    \\\\\n",
       "\\textbf{Time:}             &      12:13:55      & \\textbf{  Log-Likelihood:    } &   -3732.0   \\\\\n",
       "\\textbf{No. Observations:} &         1000       & \\textbf{  AIC:               } &     7468.   \\\\\n",
       "\\textbf{Df Residuals:}     &          998       & \\textbf{  BIC:               } &     7478.   \\\\\n",
       "\\textbf{Df Model:}         &            1       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &      cluster       & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}  &      75.2876  &        1.010     &    74.559  &         0.000        &       73.309    &       77.267     \\\\\n",
       "\\textbf{Salary} &   -5.786e-06  &     3.87e-05     &    -0.149  &         0.881        &    -8.17e-05    &     7.01e-05     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.167 & \\textbf{  Durbin-Watson:     } &    2.060  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.920 & \\textbf{  Jarque-Bera (JB):  } &    0.200  \\\\\n",
       "\\textbf{Skew:}          &  0.030 & \\textbf{  Prob(JB):          } &    0.905  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.967 & \\textbf{  Cond. No.          } & 6.28e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are robust to cluster correlation (cluster) \\newline\n",
       " [2] The condition number is large, 6.28e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      Performance_Score   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                   0.02232\n",
       "Date:                Sat, 20 Jan 2024   Prob (F-statistic):              0.888\n",
       "Time:                        12:13:55   Log-Likelihood:                -3732.0\n",
       "No. Observations:                1000   AIC:                             7468.\n",
       "Df Residuals:                     998   BIC:                             7478.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:              cluster                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         75.2876      1.010     74.559      0.000      73.309      77.267\n",
       "Salary     -5.786e-06   3.87e-05     -0.149      0.881   -8.17e-05    7.01e-05\n",
       "==============================================================================\n",
       "Omnibus:                        0.167   Durbin-Watson:                   2.060\n",
       "Prob(Omnibus):                  0.920   Jarque-Bera (JB):                0.200\n",
       "Skew:                           0.030   Prob(JB):                        0.905\n",
       "Kurtosis:                       2.967   Cond. No.                     6.28e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "[2] The condition number is large, 6.28e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reg(data, independent_variables, dependent_variable, add_const=1, robust=0, se_calc='HC3', clustering_vars=None, filtering_conditions=None):\n",
    "    \"\"\"\n",
    "    Perform linear regression with various options.\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): The dataset containing the variables.\n",
    "        independent_variables (list): A list of independent variable names.\n",
    "        dependent_variable (str): The name of the dependent variable.\n",
    "        add_const (int, optional): Whether to add a constant term (intercept) to the regression. Default is 1 (add constant).\n",
    "        robust (int, optional): Whether to use robust standard errors. Default is 0 (no robust standard errors).\n",
    "        se_calc (str, optional): The type of standard errors to calculate. Default is 'HC3'.\n",
    "        clustering_vars (list, optional): A list of variables to be used for clustering standard errors. Default is None (no clustering).\n",
    "        filtering_conditions (list, optional): A list of filtering conditions to subset the data. Each condition should be a string. Default is None (no filtering).\n",
    "\n",
    "    Returns:\n",
    "        summary (Summary): A summary of the regression results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply filtering conditions to subset the data\n",
    "    if filtering_conditions is not None:\n",
    "        # Ensure filtering_conditions is a list\n",
    "        if type(filtering_conditions) == str:\n",
    "            filtering_conditions = [filtering_conditions]\n",
    "        for cond in filtering_conditions:\n",
    "            input_str = cond\n",
    "            split_lst = input_str.split()\n",
    "            string_operator = split_lst[1]\n",
    "            # Filter the data based on the conditions\n",
    "            eval(f'data[\"{split_lst[0]}\"] {string_operator} \"{split_lst[2]}\"')\n",
    "    \n",
    "    # Extract independent and dependent variables\n",
    "    X = data[independent_variables]\n",
    "    y = data[dependent_variable]\n",
    "    \n",
    "    # Add a constant term if requested\n",
    "    if add_const == 1:\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "    # Create the regression model\n",
    "    model = sm.OLS(y, X)\n",
    "    \n",
    "    # Fit the model with various options\n",
    "    if robust == 0 and clustering_vars is None:\n",
    "        result = model.fit()\n",
    "    elif clustering_vars is None:\n",
    "        result = model.fit(cov_type=se_calc)\n",
    "    else:\n",
    "        # Ensure clustering_vars is a list\n",
    "        if type(clustering_vars) == str:\n",
    "            clustering_vars = [clustering_vars]\n",
    "        for var in clustering_vars:\n",
    "            # Create categorical codes for clustering\n",
    "            data[var + '_group'] = data[var].astype('category').cat.codes\n",
    "        # Fit the model with clustering standard errors\n",
    "        result = model.fit(cov_type='cluster', cov_kwds={'groups': data[[var+\"_group\" for var in clustering_vars]]})\n",
    "    \n",
    "    # Return a summary of the regression results\n",
    "    return result.summary()\n",
    "\n",
    "\n",
    "reg(data = df, independent_variables='Salary',\n",
    "    dependent_variable='Performance_Score', robust=1,\n",
    "    filtering_conditions=[\"Location != NY\",'Location != LA'],\n",
    "    clustering_vars = \"Department\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d52346-79eb-4075-9eb3-4420096a22b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RLM.fit() got an unexpected keyword argument 'cov_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m         result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(cov_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     21\u001b[0m                            cov_kwds\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m'\u001b[39m: data[[var\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_group\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m clustering_vars]]})\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 24\u001b[0m rreg(data \u001b[38;5;241m=\u001b[39m df, independent_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperience_Years\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m     ,dependent_variable\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance_Score\u001b[39m\u001b[38;5;124m'\u001b[39m,filtering_conditions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation == NY\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m     clustering_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartment\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m, in \u001b[0;36mrreg\u001b[0;34m(data, independent_variables, dependent_variable, add_const, clustering_vars, filtering_conditions)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m clustering_vars:\n\u001b[1;32m     19\u001b[0m         data[var \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[var]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcodes\n\u001b[0;32m---> 20\u001b[0m     result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(cov_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     21\u001b[0m                        cov_kwds\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m'\u001b[39m: data[[var\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_group\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m clustering_vars]]})\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mTypeError\u001b[0m: RLM.fit() got an unexpected keyword argument 'cov_type'"
     ]
    }
   ],
   "source": [
    "def rreg(data, independent_variables, dependent_variable, add_const = 1, clustering_vars=None,\n",
    "       filtering_conditions = None):\n",
    "    if filtering_conditions != None:\n",
    "        for cond in filtering_conditions:\n",
    "            input_str = cond\n",
    "            split_lst = input_str.split()\n",
    "            string_operator = split_lst[1]\n",
    "            eval(f'data[\"{split_lst[0]}\"] {string_operator} \"{split_lst[2]}\"')\n",
    "    X = data[independent_variables]\n",
    "    y = data[dependent_variable]\n",
    "    if add_const == 1:\n",
    "        model = sm.RLM(y, sm.add_constant(X))\n",
    "    else:\n",
    "        model = sm.RLM(y, X)\n",
    "    if clustering_vars==None:\n",
    "        result = model.fit()\n",
    "    else:\n",
    "        for var in clustering_vars:\n",
    "            data[var + '_group'] = data[var].astype('category').cat.codes\n",
    "        result = model.fit(cov_type='cluster', \n",
    "                           cov_kwds={'groups': data[[var+\"_group\" for var in clustering_vars]]})\n",
    "    return result.summary()\n",
    "\n",
    "rreg(data = df, independent_variables=['Salary','Experience_Years']\n",
    "    ,dependent_variable='Performance_Score',filtering_conditions=[\"Location == NY\"],\n",
    "    clustering_vars=['Department'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f375eeb0-ef73-4879-8a10-50838a85a9a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Series can only be used with a 2-level MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(cov_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbartlett\u001b[39m\u001b[38;5;124m'\u001b[39m, cluster_entity\u001b[38;5;241m=\u001b[39mcluster_entity)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\u001b[38;5;241m.\u001b[39msummary\n\u001b[0;32m---> 28\u001b[0m rreg(data\u001b[38;5;241m=\u001b[39mdf, independent_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperience_Years\u001b[39m\u001b[38;5;124m'\u001b[39m], dependent_variable\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, filtering_conditions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNY\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m], clustering_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartment\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m, in \u001b[0;36mrreg\u001b[0;34m(data, independent_variables, dependent_variable, add_const, clustering_vars, filtering_conditions)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_const \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     17\u001b[0m     X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X)\n\u001b[0;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m PanelOLS(y, X, entity_effects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, time_effects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clustering_vars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     cluster_entity \u001b[38;5;241m=\u001b[39m data[clustering_vars]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sklearn-env/lib/python3.11/site-packages/linearmodels/panel/model.py:1214\u001b[0m, in \u001b[0;36mPanelOLS.__init__\u001b[0;34m(self, dependent, exog, weights, entity_effects, time_effects, other_effects, singletons, drop_absorbed, check_rank)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1203\u001b[0m     dependent: PanelDataLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     check_rank: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1213\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1214\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dependent, exog, weights\u001b[38;5;241m=\u001b[39mweights, check_rank\u001b[38;5;241m=\u001b[39mcheck_rank)\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entity_effects \u001b[38;5;241m=\u001b[39m entity_effects\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_effects \u001b[38;5;241m=\u001b[39m time_effects\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sklearn-env/lib/python3.11/site-packages/linearmodels/panel/model.py:308\u001b[0m, in \u001b[0;36m_PanelModelBase.__init__\u001b[0;34m(self, dependent, exog, weights, check_rank)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    302\u001b[0m     dependent: PanelDataLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     check_rank: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependent \u001b[38;5;241m=\u001b[39m PanelData(dependent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDep\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m PanelData(exog, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependent\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sklearn-env/lib/python3.11/site-packages/linearmodels/panel/data.py:215\u001b[0m, in \u001b[0;36mPanelData.__init__\u001b[0;34m(self, x, var_name, convert_dummies, drop_first, copy)\u001b[0m\n\u001b[1;32m    213\u001b[0m     x \u001b[38;5;241m=\u001b[39m DataFrame(x)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Series):\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries can only be used with a 2-level MultiIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, DataFrame):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n",
      "\u001b[0;31mValueError\u001b[0m: Series can only be used with a 2-level MultiIndex"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from linearmodels.panel import PanelOLS\n",
    "from linearmodels.panel import FamaMacBeth\n",
    "\n",
    "def rreg(data, independent_variables, dependent_variable, add_const=1, clustering_vars=None, filtering_conditions=None):\n",
    "    if filtering_conditions is not None:\n",
    "        for cond in filtering_conditions:\n",
    "            input_str = cond\n",
    "            split_lst = input_str.split()\n",
    "            string_operator = split_lst[1]\n",
    "            data = data[eval(f'data[\"{split_lst[0]}\"] {string_operator} \"{split_lst[2]}\"')]\n",
    "    \n",
    "    X = data[independent_variables]\n",
    "    y = data[dependent_variable]\n",
    "    \n",
    "    if add_const == 1:\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "    model = PanelOLS(y, X, entity_effects=True, time_effects=False)\n",
    "    \n",
    "    if clustering_vars is not None:\n",
    "        cluster_entity = data[clustering_vars].astype('category')\n",
    "        model = FamaMacBeth(y, X, entity_effects=True)\n",
    "    \n",
    "    results = model.fit(cov_type='kernel', kernel='bartlett', cluster_entity=cluster_entity)\n",
    "    return results.summary\n",
    "\n",
    "rreg(data=df, independent_variables=['Salary', 'Experience_Years'], dependent_variable='Performance_Score', filtering_conditions=[\"Location == 'NY'\"], clustering_vars=['Department'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f1f8f6-4382-4b48-9336-3fd384e2342f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn-env]",
   "language": "python",
   "name": "conda-env-sklearn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
